{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3559561e",
   "metadata": {},
   "source": [
    "# <font color=#025dfa> Derin Öğrenme Regresyon ile Amazon İçin Önerilen Sistemi - Recommended System for Amazon with Deep Learning Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b79c37a",
   "metadata": {},
   "source": [
    "TR = Her yorum satırı kendisini üstündeki koda aittir. İlk olarak Türkçe, son olarak İngilizce yazıldı.\n",
    "\n",
    "EN = Each comment line belongs to the code above it. It was first written in Turkish and lastly in English.\n",
    "\n",
    "TR = Bu proje, Amazon platformu için kullanıcıların satın alma davranışlarını analiz ederek kişiselleştirilmiş öneriler sunan bir regresyon modeli geliştirmeyi hedeflemektedir. Kullanıcıların geçmiş alışveriş verileri, ürün özellikleri ve kullanıcı profilleri gibi çeşitli veriler kullanılarak, kullanıcıların ilgisini çekebilecek ürünlerin tahmin edilmesi sağlanacaktır. Derin öğrenme teknikleri ile desteklenen bu öneri sistemi, kullanıcı deneyimini iyileştirmek ve satışları artırmak amacıyla daha etkili ve doğru öneriler sunmayı amaçlamaktadır. Proje, e-ticaret sektöründe rekabet avantajı elde etmek için veri odaklı karar verme süreçlerini güçlendirmeyi hedeflemektedir.\n",
    "\n",
    "EN = This project aims to develop a regression model that analyzes users' purchasing behaviors for the Amazon platform and provides personalized recommendations. Various data such as users' past shopping data, product features, and user profiles will be used to predict products that may interest users. Supported by deep learning techniques, this recommendation system aims to provide more effective and accurate recommendations to improve user experience and increase sales. The project aims to strengthen data-driven decision-making processes to gain competitive advantage in the e-commerce sector.\n",
    "\n",
    "Kaynak/Source = https://www.kaggle.com/competitions/recommended-system-for-amazon-icl-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15fce1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy import spatial #harital üzerindeki mesafeyi ölçüyor\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization,Flatten, LeakyReLU\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler,MinMaxScaler\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3179c9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d3ac721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           userId   productId  Rating\n",
      "0   AOPE42H34R0EC  B00000DM9W     5.0\n",
      "1  A1GI09JC6L0NF7  B00004SABJ     4.0\n",
      "2   AZLZII4AFX56R  B00000J579     3.0\n",
      "3  A34AHNT6GD9FWW  9888002198     5.0\n",
      "4  A2PXRAO5C1XTLW  0972683275     5.0\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52889019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               userId   productId  Rating\n",
      "17343  A2KFK3WT8VAJC5  B00004SPUN     5.0\n",
      "20627  A1DQGI584UAKRI  B00001WRSJ     5.0\n",
      "2410   A3R3A8D3D9JVWU  B00000J3H5     5.0\n",
      "15640  A228FCKXMDRW59  B00000J434     5.0\n",
      "7515   A1R7POV8N6O5MZ  B00004R8V6     5.0\n"
     ]
    }
   ],
   "source": [
    "print(df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6129efe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               userId   productId  Rating\n",
      "33970  A22GYGQ14GHSCD  B00004TDLD     5.0\n",
      "33971  A2O30HQWWYD5FH  B000038ABH     5.0\n",
      "33972  A37OTRJO1NM63H  B00003ETSJ     1.0\n",
      "33973  A2SLR2VUDUGCQM  B00004TDLD     5.0\n",
      "33974  A339ZN69W7N8PW  B00001P4XH     4.0\n"
     ]
    }
   ],
   "source": [
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2f862d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33975, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "905b75f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33975 entries, 0 to 33974\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   userId     33975 non-null  object \n",
      " 1   productId  33975 non-null  object \n",
      " 2   Rating     33975 non-null  float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 796.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f10873d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId       0\n",
      "productId    0\n",
      "Rating       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum().sort_values(ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b4633e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId       A38YWVKHDGWXFF\n",
       "productId        B00004T8R2\n",
       "Rating                  5.0\n",
       "Name: 195, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[195]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0808c607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId       A3B2X7BT9UCAR3\n",
       "productId        B00000J40W\n",
       "Rating                  4.0\n",
       "Name: 241, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[241]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0d7091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rating']=df['Rating'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9e85528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating\n",
       "5    19004\n",
       "4     6958\n",
       "1     3492\n",
       "3     2659\n",
       "2     1862\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46964eae",
   "metadata": {},
   "source": [
    "## <font color=#FFD700> Popülerliğe Dayalı - Popularity Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df9b7a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_grouped = df.groupby('productId').agg({'Rating': [np.size, np.sum, np.mean]})\n",
    "# TR = ratings veri setini 'title' sütununa göre gruplayıp, her film için 'rating' sütununda 3 farklı istatistiği hesaplıyoruz:\n",
    "#     np.size ile kaç değerlendirme yapıldığını (sayısı),\n",
    "#     np.sum ile toplam değerlendirme puanını,\n",
    "#     np.mean ile ortalama değerlendirme puanını hesaplıyoruz.\n",
    "\n",
    "# EN = We are grouping the ratings dataset by the 'title' column, and calculating 3 different statistics for the 'rating' column:\n",
    "#     np.size to get the number of ratings (count),\n",
    "#     np.sum to get the total rating score,\n",
    "#     np.mean to get the average rating score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68c25003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0528881469</th>\n",
       "      <td>18</td>\n",
       "      <td>48</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0594033926</th>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "      <td>4.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0594451647</th>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>4.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0594481813</th>\n",
       "      <td>28</td>\n",
       "      <td>118</td>\n",
       "      <td>4.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0594481902</th>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00004THPR</th>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "      <td>4.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00004THQ0</th>\n",
       "      <td>19</td>\n",
       "      <td>67</td>\n",
       "      <td>3.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00004THQ5</th>\n",
       "      <td>18</td>\n",
       "      <td>67</td>\n",
       "      <td>3.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00004TIZS</th>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>3.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00004TJ0L</th>\n",
       "      <td>18</td>\n",
       "      <td>81</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>737 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Rating               \n",
       "             size  sum      mean\n",
       "productId                       \n",
       "0528881469     18   48  2.666667\n",
       "0594033926     10   44  4.400000\n",
       "0594451647     12   51  4.250000\n",
       "0594481813     28  118  4.214286\n",
       "0594481902     12   52  4.333333\n",
       "...           ...  ...       ...\n",
       "B00004THPR     10   43  4.300000\n",
       "B00004THQ0     19   67  3.526316\n",
       "B00004THQ5     18   67  3.722222\n",
       "B00004TIZS     13   48  3.692308\n",
       "B00004TJ0L     18   81  4.500000\n",
       "\n",
       "[737 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edc6b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "populer_product = product_grouped.sort_values(('Rating', 'mean'), ascending=False)\n",
    "# TR = movie_grouped veri setini 'rating' sütununun 'mean' (ortalama) değerine göre azalan sırayla sıralıyoruz.\n",
    "#     Bu, en yüksek ortalama puana sahip filmleri en üste getirir.\n",
    "\n",
    "# EN = We are sorting the movie_grouped dataset by the 'mean' (average) value of the 'rating' column in descending order.\n",
    "#     This brings the movies with the highest average ratings to the top.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a55119e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B00000J3NE</th>\n",
       "      <td>17</td>\n",
       "      <td>85</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00004S54K</th>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00002EQBU</th>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00002NAXD</th>\n",
       "      <td>12</td>\n",
       "      <td>60</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00000JDFI</th>\n",
       "      <td>11</td>\n",
       "      <td>55</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Rating         \n",
       "             size sum mean\n",
       "productId                 \n",
       "B00000J3NE     17  85  5.0\n",
       "B00004S54K      8  40  5.0\n",
       "B00002EQBU      7  35  5.0\n",
       "B00002NAXD     12  60  5.0\n",
       "B00000JDFI     11  55  5.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "populer_product.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ac7972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_sum = product_grouped['Rating']['sum'].sum()\n",
    "# TR = movie_grouped veri setindeki 'rating' sütununun 'sum' (toplam) değerlerini topluyoruz. \n",
    "#     Bu, tüm filmler için toplam değerlendirme puanlarını toplar.\n",
    "\n",
    "# EN = We are summing the 'sum' values from the 'rating' column in the movie_grouped dataset.\n",
    "#     This gives the total rating score across all movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7667b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "populer_product['percentage'] = product_grouped['Rating']['sum'].div(grouped_sum) * 100\n",
    "# TR = movie_grouped veri setindeki her bir filmin 'rating' sütunundaki 'sum' (toplam) değerini, grouped_sum (tüm filmlerin toplam değerlendirme puanı) ile bölüyoruz.\n",
    "#     Sonucu 100 ile çarparak, her filmin toplam değerlendirme puanının tüm filmler arasındaki yüzdesini hesaplıyoruz.\n",
    "\n",
    "# EN = We are dividing the 'sum' (total) value from the 'rating' column in the movie_grouped dataset by grouped_sum (the total rating score for all movies).\n",
    "#     We multiply the result by 100 to calculate the percentage of each movie's total rating score relative to the total across all movies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "358b756e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Rating</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B00000J3NE</th>\n",
       "      <td>17</td>\n",
       "      <td>85</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.061574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00004S54K</th>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.028976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00002EQBU</th>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.025354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00002NAXD</th>\n",
       "      <td>12</td>\n",
       "      <td>60</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.043464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00000JDFI</th>\n",
       "      <td>11</td>\n",
       "      <td>55</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.039842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Rating          percentage\n",
       "             size sum mean           \n",
       "productId                            \n",
       "B00000J3NE     17  85  5.0   0.061574\n",
       "B00004S54K      8  40  5.0   0.028976\n",
       "B00002EQBU      7  35  5.0   0.025354\n",
       "B00002NAXD     12  60  5.0   0.043464\n",
       "B00000JDFI     11  55  5.0   0.039842"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "populer_product.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e011ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "populer_product = populer_product.sort_values('percentage', ascending=False)\n",
    "# TR = populer_movies veri setini 'percentage' sütununa göre azalan sırayla sıralıyoruz.\n",
    "#     Bu, en yüksek yüzdelik değere sahip filmleri en üste getirir.\n",
    "# EN = We are sorting the populer_movies dataset by the 'percentage' column in descending order.\n",
    "#     This brings the movies with the highest percentage values to the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7011deaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Rating</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B00001P4ZH</th>\n",
       "      <td>1682</td>\n",
       "      <td>7486</td>\n",
       "      <td>4.450654</td>\n",
       "      <td>5.422869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00001WRSJ</th>\n",
       "      <td>1280</td>\n",
       "      <td>5897</td>\n",
       "      <td>4.607031</td>\n",
       "      <td>4.271795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00004T8R2</th>\n",
       "      <td>1379</td>\n",
       "      <td>5880</td>\n",
       "      <td>4.263959</td>\n",
       "      <td>4.259481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0972683275</th>\n",
       "      <td>824</td>\n",
       "      <td>3701</td>\n",
       "      <td>4.491505</td>\n",
       "      <td>2.681010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00004SABB</th>\n",
       "      <td>796</td>\n",
       "      <td>3200</td>\n",
       "      <td>4.020101</td>\n",
       "      <td>2.318085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0899336795</th>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.010866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00000JH72</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.010866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9269807207</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.010142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00000J4DT</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.005795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00000JII9</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.004346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>737 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Rating                 percentage\n",
       "             size   sum      mean           \n",
       "productId                                   \n",
       "B00001P4ZH   1682  7486  4.450654   5.422869\n",
       "B00001WRSJ   1280  5897  4.607031   4.271795\n",
       "B00004T8R2   1379  5880  4.263959   4.259481\n",
       "0972683275    824  3701  4.491505   2.681010\n",
       "B00004SABB    796  3200  4.020101   2.318085\n",
       "...           ...   ...       ...        ...\n",
       "0899336795      9    15  1.666667   0.010866\n",
       "B00000JH72     10    15  1.500000   0.010866\n",
       "9269807207      8    14  1.750000   0.010142\n",
       "B00000J4DT      5     8  1.600000   0.005795\n",
       "B00000JII9      5     6  1.200000   0.004346\n",
       "\n",
       "[737 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "populer_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "630bdf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "populer_product['Rank'] = populer_product['percentage'].rank(ascending=False)\n",
    "# TR = populer_movies veri setindeki 'percentage' sütununa göre her filme bir sıralama (rank) numarası veriyoruz.\n",
    "#     Bu sıralama, yüzdelik değerlere göre azalan sırayla yapılır, yani en yüksek yüzdelik değere sahip film birinci sıradadır.\n",
    "\n",
    "# EN = We are assigning a rank to each movie in the populer_movies dataset based on the 'percentage' column.\n",
    "#     The ranking is done in descending order, meaning the movie with the highest percentage gets the top rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f9a4022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Rating</th>\n",
       "      <th>percentage</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B00001P4ZH</th>\n",
       "      <td>1682</td>\n",
       "      <td>7486</td>\n",
       "      <td>4.450654</td>\n",
       "      <td>5.422869</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00001WRSJ</th>\n",
       "      <td>1280</td>\n",
       "      <td>5897</td>\n",
       "      <td>4.607031</td>\n",
       "      <td>4.271795</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00004T8R2</th>\n",
       "      <td>1379</td>\n",
       "      <td>5880</td>\n",
       "      <td>4.263959</td>\n",
       "      <td>4.259481</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0972683275</th>\n",
       "      <td>824</td>\n",
       "      <td>3701</td>\n",
       "      <td>4.491505</td>\n",
       "      <td>2.681010</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00004SABB</th>\n",
       "      <td>796</td>\n",
       "      <td>3200</td>\n",
       "      <td>4.020101</td>\n",
       "      <td>2.318085</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Rating                 percentage Rank\n",
       "             size   sum      mean                \n",
       "productId                                        \n",
       "B00001P4ZH   1682  7486  4.450654   5.422869  1.0\n",
       "B00001WRSJ   1280  5897  4.607031   4.271795  2.0\n",
       "B00004T8R2   1379  5880  4.263959   4.259481  3.0\n",
       "0972683275    824  3701  4.491505   2.681010  4.0\n",
       "B00004SABB    796  3200  4.020101   2.318085  5.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "populer_product.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5420c74e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "284e8c72",
   "metadata": {},
   "source": [
    "## <font color='#0F52BA'> Öznitelik Mühendisliği - Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa38009",
   "metadata": {},
   "source": [
    "### <font color=#007fff> Model - Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3421302f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b547768d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>productId</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AOPE42H34R0EC</td>\n",
       "      <td>B00000DM9W</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId   productId  Rating\n",
       "0  AOPE42H34R0EC  B00000DM9W       5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7238cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Rating', axis=1)\n",
    "y = df['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25bb1daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.get_dummies(x,drop_first=True)\n",
    "# Tr =  kategorik değişkenlerin sayısal değişkenlere dönüştürülmesi için kullanılır.\n",
    "# En = It is used to convert categorical variables into numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1aff026",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.fillna(0, inplace=True)\n",
    "y.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4abeb9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "# TR = Veriyi eğitim ve test seti olarak ayırır; %20 test seti, %80 eğitim seti olacak şekilde bölünür\n",
    "# EN = Splits the data into training and test sets; 20% for the test set and 80% for the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27e59cab",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 6.71 GiB for an array with shape (33119, 27180) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# TR = Avantajları:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# TR = Negatif ve pozitif değerler içeren verilerde performansı artırabilir.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# TR = Aykırı değerlere karşı daha dayanıklıdır.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# EN = Disadvantages:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# EN = Does not fit the data into a specific range (e.g., between 0 and 1).\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m x_train \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(x_train)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# TR = Verileri ölçekleyerek, modelin daha hızlı ve etkili öğrenmesini sağlamak için tüm özellikleri aynı aralığa getiriyoruz.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# EN = By scaling the data, we bring all the features into the same range to allow the model to learn faster and more effectively.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m x_test \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(x_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:878\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:914\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \n\u001b[0;32m    884\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    913\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 914\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    915\u001b[0m     X,\n\u001b[0;32m    916\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    917\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[0;32m    918\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    919\u001b[0m     reset\u001b[38;5;241m=\u001b[39mfirst_call,\n\u001b[0;32m    920\u001b[0m )\n\u001b[0;32m    921\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:745\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    743\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 745\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:2083\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2082\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2083\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   2084\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   2085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2086\u001b[0m         astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   2087\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[0;32m   2088\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block\n\u001b[0;32m   2089\u001b[0m     ):\n\u001b[0;32m   2090\u001b[0m         \u001b[38;5;66;03m# Check if both conversions can be done without a copy\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:1046\u001b[0m, in \u001b[0;36mDataFrame._values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1044\u001b[0m blocks \u001b[38;5;241m=\u001b[39m mgr\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(blocks) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1046\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ensure_wrapped_if_datetimelike(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m   1048\u001b[0m arr \u001b[38;5;241m=\u001b[39m blocks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# non-2D ExtensionArray\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:12281\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  12207\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m  12208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m  12209\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m  12210\u001b[0m \u001b[38;5;124;03m    Return a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[0;32m  12211\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12279\u001b[0m \u001b[38;5;124;03m           ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[0;32m  12280\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 12281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mas_array()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1656\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1654\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1656\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interleave(dtype\u001b[38;5;241m=\u001b[39mdtype, na_value\u001b[38;5;241m=\u001b[39mna_value)\n\u001b[0;32m   1657\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1689\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1686\u001b[0m \u001b[38;5;66;03m# error: Argument 1 to \"ensure_np_dtype\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;66;03m# \"Optional[dtype[Any]]\"; expected \"Union[dtype[Any], ExtensionDtype]\"\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m dtype \u001b[38;5;241m=\u001b[39m ensure_np_dtype(dtype)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m-> 1689\u001b[0m result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1691\u001b[0m itemmask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;66;03m# much more performant than using to_numpy below\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 6.71 GiB for an array with shape (33119, 27180) and data type float64"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "# TR = Avantajları:\n",
    "# TR = Negatif ve pozitif değerler içeren verilerde performansı artırabilir.\n",
    "# TR = Aykırı değerlere karşı daha dayanıklıdır.\n",
    "# TR = Dezavantajları:\n",
    "# TR = Veriyi kesin bir aralığa sığdırmaz (örneğin, 0 ile 1 arasında).\n",
    "\n",
    "# EN = Advantages:\n",
    "# EN = Can improve performance for data containing both negative and positive values.\n",
    "# EN = More robust to outliers.\n",
    "# EN = Disadvantages:\n",
    "# EN = Does not fit the data into a specific range (e.g., between 0 and 1).\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "# TR = Verileri ölçekleyerek, modelin daha hızlı ve etkili öğrenmesini sağlamak için tüm özellikleri aynı aralığa getiriyoruz.\n",
    "# EN = By scaling the data, we bring all the features into the same range to allow the model to learn faster and more effectively.\n",
    "\n",
    "x_test = scaler.transform(x_test)\n",
    "# TR = Test verilerini eğitimde kullanılan aynı ölçekle dönüştürerek modelin test verileri üzerinde doğru tahminler yapmasını sağlar.\n",
    "# EN = It enables the model to make accurate predictions on the test data by transforming the test data to the same scale used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b0cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# TR = Modelin katmanlarını sırayla eklemek için Sequential kullanıyoruz.\n",
    "# EN = We use Sequential to add layers of the model in order.\n",
    "\n",
    "model.add(Dense(128, input_dim=x_train.shape[1]))\n",
    "# TR = 128 nöronlu bir katman ekliyoruz.\n",
    "# TR = input_dim=x_train.shape[1] Modelin ilk katmanına giriş verilerinin boyutunu tanımlayarak her özelliğin doğru şekilde işlenmesini sağlar.\n",
    "\n",
    "# EN = We add a layer with 128 neurons.\n",
    "# EN = input_dim=x_train.shape[1] Defines the size of the input data in the first layer of the model, ensuring that each feature is processed correctly.\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(32))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# TR = Regresyon görevleri için lineer aktivasyon kullanıyoruz.\n",
    "# EN = We use linear activation for regression tasks.\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['mean_squared_error'])\n",
    "# TR = Modeli ortalama kare hata (mse) kaybı ile derliyoruz.\n",
    "# EN = We compile the model with mean square error (mse) loss.\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "# TR = EarlyStopping ekleyin: Eğitim sırasında model performansı iyileşmediğinde erken durması için kullanıyoruz.\n",
    "# EN = Add EarlyStopping: We use it to stop early when model performance does not improve during training.\n",
    "\n",
    "# TR = val_loss 10 epoch boyunca iyileşmezse eğitimi durduruyor ve en iyi ağırlıkları geri yüklüyor.\n",
    "# EN = If val_loss does not improve for 10 epochs, it stops training and restores the best weights.\n",
    "\n",
    "history=model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=128, epochs=100, callbacks=[early_stopping])\n",
    "# TR = Modeli 100 epoch boyunca eğitiyoruz, fakat EarlyStopping ile durdurulabilir. Batch boyutu 128 olarak belirlenmiş.\n",
    "# EN = We train the model for 100 epochs, but it can be stopped with EarlyStopping. Batch size is set to 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3de4b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9170d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = model.evaluate(x_test, y_test)\n",
    "\n",
    "# TR = İlk eleman kayıp değerini, ikinci eleman ise hesaplanan ek metriği içerir.\n",
    "# EN = The first element contains the loss value, the second contains the additional metric.\n",
    "\n",
    "print(f\"Test kaybı: {test_loss[0]:.4f}\")\n",
    "print(f\"Mean Squared Error: {test_loss[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c4a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "# TR = modeli x_test ile predict özelliği ile tahmin ettik. predict=tahmin demek. Dahmin edip pred eşitledik.\n",
    "# EN = We predicted the model with x_test and the predict feature. predict=means prediction. We guessed and equalized the pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1061b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, pred)\n",
    "# TR = Bunu gerçek(y_test) değer ile tahmin(pred) edilen değerleri karşılaştır ve arasındaki farkı bul.\n",
    "# EN = Compare this with the actual (y_test) value and the predicted (pred) values ​​and find the difference between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df65a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,pred)**.5\n",
    "# TR = Burada, Root Mean Square Error bulduk. Bunu gerçek(y_test) değer ile tahmin(pred) edilen değerleri karşılaştır arasındaki farkı bul ve **.5 ile karekökünü al.\n",
    "# EN = Here, we found Root Mean Square Error. Compare this with the actual (y_test) value and the predicted (pred) values, find the difference and take the square root of **.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bcd534",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test,pred)\n",
    "# TR = mean_absolute_error ile (y_test,pred) kullanarak değerini hesaplama. \n",
    "# EN = Calculating the value of mean_absolute_error using (y_test,pred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e8294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals=y_test-pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f6825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(x=residuals,fill=True);\n",
    "# TR = Veri dağılımını pürüzsüz bir şekilde tahmin etmek için kullanılan bir yoğunluk grafiğidir. Kernel Yoğunluk Tahmini (KDE) ile verinin altında yatan olasılık dağılımını görselleştirir.\n",
    "# EN = It is a density plot used to smoothly estimate the distribution of data. It visualizes the underlying probability distribution of data using Kernel Density Estimation (KDE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1933b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f=pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e12e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ddacf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model,open('Amazon.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 2671877,
     "sourceId": 31137,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
